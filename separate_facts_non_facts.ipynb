{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gensim\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from spacy.lang.fr import French\n",
    "from src.models import SentenceClassifier\n",
    "from src.dataset import Lexicon, tensorFromSentence, DocumentDataset\n",
    "from src.util import padSentence, getOffsets, getBestSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "device = torch.device(\"cuda\")\n",
    "df = pd.read_csv(\"dataset_10k.csv\", low_memory=False)\n",
    "nlp = French()\n",
    "sbd = nlp.create_pipe('sentencizer')\n",
    "nlp.add_pipe(sbd)\n",
    "embeddings_file = \"../frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin\"\n",
    "embeddings = gensim.models.KeyedVectors.load_word2vec_format(embeddings_file, binary=True, unicode_errors='ignore')\n",
    "embeddings_tensor = torch.FloatTensor(embeddings.vectors)\n",
    "lexicon = Lexicon(embeddings)\n",
    "model = SentenceClassifier(embeddings_tensor).to(device)\n",
    "model.load_state_dict(torch.load(\"models/sentence_clf.pt\"))\n",
    "dataset = DocumentDataset(ds_loc=\"data/camemBERT_representations_64/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1][\"Facts\"] == df.iloc[0][\"Facts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261804c597ae43a68efbe451ec6fc670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Gathering offsets', max=10360, style=ProgressStyle(descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9259133293995797\n",
      "pre: 0.919437758302076\n",
      "rec: 0.9206487344421237\n",
      "f1: 0.9113609863281781\n"
     ]
    }
   ],
   "source": [
    "offsets = []\n",
    "acc = []\n",
    "pre = []\n",
    "rec = []\n",
    "f1 = []\n",
    "for i in tqdm(range(10360), desc=\"Gathering offsets\"):\n",
    "    doc = df.iloc[i][\"Facts\"] + df.iloc[i][\"Analyses\"]\n",
    "    doc = doc.replace(\"- \",\". \").replace(\";\",\".\").replace(\"\\n\",\" \").replace(\":\", \".\")\n",
    "    doc = nlp(doc)\n",
    "    doc = list(doc.sents)\n",
    "    doc = [str(sentence) for sentence in doc]\n",
    "    doc_len = len(doc)\n",
    "#     print(doc_len)\n",
    "    doc = [sentence for sentence in doc if len(sentence) > 3]\n",
    "    sentences = []\n",
    "    for sentence in doc:\n",
    "        sentence = tensorFromSentence(lexicon, sentence).to(device)\n",
    "        sentence = padSentence(sentence)\n",
    "        output = model(sentence.unsqueeze(0), lengths=torch.tensor([len(sentence)]).to(device))\n",
    "        output = output.item()\n",
    "        output = round(output)\n",
    "        sentences.append(output)\n",
    "#         print(sentences)\n",
    "    doc = len(getBestSplit(sentences, gamma=1))\n",
    "    \n",
    "    facts = df.iloc[i][\"Facts\"]\n",
    "    facts = facts.replace(\"- \",\". \").replace(\";\",\".\").replace(\"\\n\",\" \").replace(\":\", \".\")\n",
    "    facts = nlp(facts)\n",
    "    facts = list(facts.sents)\n",
    "    facts = [str(sentence) for sentence in facts]\n",
    "    facts = [sentence for sentence in facts if len(sentence) > 3]\n",
    "    facts = len(facts)\n",
    "    offsets.append(doc - facts)\n",
    "    doc = torch.tensor(sentences)\n",
    "    doc = torch.nn.functional.pad(doc, pad=(0, doc_len-len(doc)))\n",
    "    facts = torch.ones(facts)\n",
    "    facts = torch.nn.functional.pad(facts, pad=(0, doc_len-len(facts)))\n",
    "#     print(doc.shape, facts.shape)\n",
    "    acc.append(accuracy_score(doc, facts))\n",
    "    pre.append(precision_score(doc, facts))\n",
    "    rec.append(recall_score(doc, facts))\n",
    "    f1.append(f1_score(doc, facts))\n",
    "#     print(\"SENTS: {}\".format(sentences))\n",
    "\n",
    "acc = sum(acc)/len(acc)\n",
    "pre = sum(pre)/len(pre)\n",
    "rec = sum(rec)/len(rec)\n",
    "f1 = sum(f1)/len(f1)\n",
    "print(\"acc: {}\".format(acc))\n",
    "print(\"pre: {}\".format(pre))\n",
    "print(\"rec: {}\".format(rec))\n",
    "print(\"f1: {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<-4': 2810,\n",
       " '-4': 135,\n",
       " '-3': 92,\n",
       " '-2': 127,\n",
       " '-1': 95,\n",
       " '0': 2291,\n",
       " '1': 4573,\n",
       " '2': 180,\n",
       " '3': 35,\n",
       " '4': 6,\n",
       " '>4': 16}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOffsets(offsets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
