{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/andres/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    }
   ],
   "source": [
    "camembert = torch.hub.load('pytorch/fairseq', 'camembert.v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactsOrAnalysisDS_BERT(Dataset):\n",
    "    \"\"\"PyTorch Dataset class. Returns input-target tensor pairs\"\"\"\n",
    "    def __init__(self,csv_file):\n",
    "        camembert = torch.hub.load('pytorch/fairseq', 'camembert.v0')\n",
    "        with open(csv_file) as f:\n",
    "            dataset=[line.split(\",\") for line in f]\n",
    "        self.dataset=[[camembert.encode(datum[0]),int(datum[1][0])] for datum in dataset]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.dataset))\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.dataset[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=\"data/train_data.csv\"\n",
    "with open(data_file) as f:\n",
    "    dataset=[line.split(\",\") for line in f]\n",
    "dataset=[[pair[0].replace(\"\\n\",\"\"),pair[1].replace(\"\\n\",\"\")] for pair in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/andres/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    }
   ],
   "source": [
    "dataset_camembert=FactsOrAnalysisDS_BERT(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "rnn=torch.nn.GRU(\n",
    "    input_size=768,\n",
    "    hidden_size=64,\n",
    "    num_layers=3,\n",
    "    batch_first=True,\n",
    "    bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    5,    22,    44,    31,  1307,    16, 11938, 19299,    16,    17,\n",
       "          1920,  1569,  9046,    27,    16,  9813,   111,   279,    13,  2124,\n",
       "             8,   191,    16, 11938,     8,   742,    15,   652,     6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u=dataset_camembert[90][0].unsqueeze(0)\n",
    "# u=u.unsqueeze(0)\n",
    "# u=camembert.encode(u)\n",
    "# u=camembert.extract_features(u)\n",
    "# u,v=rnn(u)\n",
    "# v.shape\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0574,  0.1625,  0.1480,  ..., -0.0822, -0.0142,  0.0169],\n",
       "         [-0.0104,  0.3305,  0.2646,  ..., -0.1891,  0.0838, -0.0138],\n",
       "         [ 0.0456,  0.2597, -0.0835,  ...,  0.0257,  0.1584,  0.0653],\n",
       "         ...,\n",
       "         [ 0.1277,  0.1146,  0.0857,  ...,  0.0499,  0.0650, -0.1046],\n",
       "         [-0.0506, -0.3077, -0.1230,  ..., -0.0575,  0.0098,  0.2734],\n",
       "         [-0.0287,  0.1020,  0.1440,  ..., -0.0635,  0.0814,  0.1171]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camembert.train()\n",
    "camembert.extract_features(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have to rewrite the `Dataset` class to accomodate camemBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class camembertTest(torch.nn.Module):\n",
    "    def __init__(self,cam):\n",
    "        super(camembertTest, self).__init__()\n",
    "        self.camembert=cam\n",
    "#         self.camembert.eval()\n",
    "        \n",
    "    def forward(self,seq):\n",
    "        return self.camembert.extract_features(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=camembertTest(camembert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0633,  0.0881,  0.0851,  ...,  0.0363, -0.0519,  0.0749],\n",
       "         [-0.0524,  0.3216,  0.2259,  ..., -0.1883,  0.0476,  0.0619],\n",
       "         [ 0.0397,  0.1794, -0.1710,  ...,  0.0063,  0.0882,  0.0660],\n",
       "         ...,\n",
       "         [ 0.0571,  0.1803, -0.0355,  ..., -0.0590,  0.0469, -0.1190],\n",
       "         [-0.0356, -0.2203, -0.1231,  ...,  0.0677,  0.0151,  0.2744],\n",
       "         [-0.0027,  0.1280,  0.1507,  ..., -0.0694, -0.0657,  0.0486]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "camembertTest(\n",
       "  (camembert): RobertaHubInterface(\n",
       "    (model): RobertaModel(\n",
       "      (decoder): RobertaEncoder(\n",
       "        (sentence_encoder): TransformerSentenceEncoder(\n",
       "          (embed_tokens): Embedding(32005, 768, padding_idx=1)\n",
       "          (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
       "          (layers): ModuleList(\n",
       "            (0): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (1): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (2): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (3): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (4): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (5): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (6): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (7): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (8): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (9): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (10): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (11): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (emb_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (lm_head): RobertaLMHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (classification_heads): ModuleDict()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0557,  0.0921, -0.0298,  ..., -0.0734,  0.0880,  0.0880],\n",
       "         [-0.0278,  0.2673,  0.1886,  ..., -0.1658,  0.0726, -0.0252],\n",
       "         [-0.0204,  0.2479, -0.3003,  ...,  0.0726,  0.1601,  0.1031],\n",
       "         ...,\n",
       "         [ 0.1874, -0.0342, -0.0286,  ..., -0.0705,  0.0729, -0.1227],\n",
       "         [-0.1576, -0.2899, -0.1430,  ...,  0.0161, -0.0232,  0.3373],\n",
       "         [ 0.0415,  0.1347,  0.1356,  ..., -0.0966, -0.0670,  0.1503]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(u)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
